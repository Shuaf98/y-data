{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom scipy import stats\nimport xgboost as xgb","metadata":{"id":"0ezWI0a-giLp","execution":{"iopub.status.busy":"2022-01-31T18:19:22.039464Z","iopub.execute_input":"2022-01-31T18:19:22.040017Z","iopub.status.idle":"2022-01-31T18:19:23.605154Z","shell.execute_reply.started":"2022-01-31T18:19:22.039918Z","shell.execute_reply":"2022-01-31T18:19:23.604275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking training set\ntrain  = pd.read_csv('../input/house-price-feature-eng/train.csv')\npd.set_option('display.max_rows', train.shape[0]+1)\ntrain.head().T","metadata":{"id":"nkfIYniEitnF","outputId":"4c9c88be-e974-40cc-9ff1-b1a35cb44d42","execution":{"iopub.status.busy":"2022-01-31T18:19:23.608674Z","iopub.execute_input":"2022-01-31T18:19:23.608957Z","iopub.status.idle":"2022-01-31T18:19:23.696682Z","shell.execute_reply.started":"2022-01-31T18:19:23.608925Z","shell.execute_reply":"2022-01-31T18:19:23.695548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking missing values\nmissingvals = train.columns[train.isnull().sum()>0]\nmean_missing = train[missingvals].isnull().mean().sort_values()\nmean_missing","metadata":{"id":"OTpibGMBiz3d","outputId":"9afd3e44-f667-4a0d-9725-0c3e5f597926","execution":{"iopub.status.busy":"2022-01-31T18:19:23.698225Z","iopub.execute_input":"2022-01-31T18:19:23.698924Z","iopub.status.idle":"2022-01-31T18:19:23.731799Z","shell.execute_reply.started":"2022-01-31T18:19:23.698833Z","shell.execute_reply":"2022-01-31T18:19:23.730903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To make sure there are no missing values even in the test set, we define categories of all columns according to the value to replace missing values. \n#For columns where values might be missing due to non-existing features such as no basement, None will be used to fill missing values\n# For other categorical folumns, Unknown will be used\n# numerical columns will be filled with either 0 or the mean value of the columns, according to what seems reasonable\n\nmissing_none = ['Condition1','Condition2','CentralAir','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageCond','GarageQual','GarageFinish','GarageType','MasVnrType','PoolQC','Fence','Exterior2nd','Heating','HeatingQC','KitchenQual','PavedDrive']\nmissing_zero = ['MasVnrArea','BsmtFinSF2','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','LowQualFinSF','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal']\nmissing_mean = ['LotArea','1stFlrSF', '2ndFlrSF', 'GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','TotRmsAbvGrd','MoSold','YrSold','YearBuilt','YearRemodAdd','BedroomAbvGr','KitchenAbvGr']\nmissing_unknown = [col for col in train.columns if col not in missing_none and col not in missing_zero and col not in missing_mean and col != 'SalePrice']","metadata":{"id":"yqnuhBkLIsjj","execution":{"iopub.status.busy":"2022-01-31T18:19:23.734402Z","iopub.execute_input":"2022-01-31T18:19:23.734733Z","iopub.status.idle":"2022-01-31T18:19:23.743883Z","shell.execute_reply.started":"2022-01-31T18:19:23.73469Z","shell.execute_reply":"2022-01-31T18:19:23.742713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Two specific columns with missing values in the training set will be filled with a specific value:\n# For Garage year built, we decided to use the building's year built as a fill value\n# For LotFrontage (road connected to the property), we used the mean of the neighborhood as a fill value\n\ndef replace_missingvals(df):\n    df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['YearBuilt'])\n    df['LotFrontage'] = df['LotFrontage'].fillna(df.groupby('Neighborhood')['LotFrontage'].transform('mean'))\n    df[missing_none] = df[missing_none].fillna('None')\n    df[missing_unknown] = df[missing_unknown].fillna('Unknown')\n    df[missing_zero] = df[missing_zero].fillna(0)\n    df[missing_mean] = df[missing_mean].fillna(df[missing_mean].mean().round())\n    return df","metadata":{"id":"irX6kptFndDW","execution":{"iopub.status.busy":"2022-01-31T18:19:23.745452Z","iopub.execute_input":"2022-01-31T18:19:23.745941Z","iopub.status.idle":"2022-01-31T18:19:23.763555Z","shell.execute_reply.started":"2022-01-31T18:19:23.745733Z","shell.execute_reply":"2022-01-31T18:19:23.762289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace missing values in the train set and make sure there are no missing values left\ntrain = replace_missingvals(train)\ntrain.columns[train.isna().sum()>0]","metadata":{"id":"qG3F4hthTtIp","outputId":"bb3edd05-8424-449c-90f6-7bd9db0d8264","execution":{"iopub.status.busy":"2022-01-31T18:19:23.764755Z","iopub.execute_input":"2022-01-31T18:19:23.765129Z","iopub.status.idle":"2022-01-31T18:19:23.822964Z","shell.execute_reply.started":"2022-01-31T18:19:23.765084Z","shell.execute_reply":"2022-01-31T18:19:23.822352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For ordinal columns, we wanted to make sure the meaning is preserved after encoding,s owe saved all the categories in the correct order\nordcols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n       'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC','LotShape','LandSlope',\n           'BsmtExposure','BsmtFinType1',\n       'BsmtFinType2', 'Functional','GarageFinish',]\nratingcols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n       'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\norddict = {\n    'LotShape':['IR3','IR2','None','IR1','Reg'],\n    'LandSlope':['Sev','Mod','Unknown','Gtl'],\n     'BsmtExposure': ['No','Mn','None','Av','Gd'],\n    'BsmtFinType1': ['Unf','LwQ','Rec','None','BLQ','ALQ','GLQ'],\n    'BsmtFinType2': ['Unf','LwQ','Rec','None','BLQ','ALQ','GLQ'],\n    'Functional':['Sal','Sev','Maj2','Maj1','Unknown','Mod','Min2','Min1','Typ'],\n    'GarageFinish':['Unf','RFn','None','Fin'],  \n}","metadata":{"id":"RfI5B2tYxhjT","execution":{"iopub.status.busy":"2022-01-31T18:19:23.823907Z","iopub.execute_input":"2022-01-31T18:19:23.824141Z","iopub.status.idle":"2022-01-31T18:19:23.832126Z","shell.execute_reply.started":"2022-01-31T18:19:23.824113Z","shell.execute_reply":"2022-01-31T18:19:23.831423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding ordinal columns\ndef ordinal_encode(df):\n    enc = OrdinalEncoder(categories = [['Po','Fa','None','TA','Gd','Ex']])\n    for col in ratingcols:\n        df[col] = enc.fit_transform(df[col].to_numpy().reshape(-1,1))\n    for col in orddict:\n        enc = OrdinalEncoder(categories = [orddict[col]])\n        df[col] = enc.fit_transform(df[col].to_numpy().reshape(-1,1))\n    return df","metadata":{"id":"Vd0zmmbY1tla","execution":{"iopub.status.busy":"2022-01-31T18:19:23.83322Z","iopub.execute_input":"2022-01-31T18:19:23.833416Z","iopub.status.idle":"2022-01-31T18:19:23.84637Z","shell.execute_reply.started":"2022-01-31T18:19:23.833393Z","shell.execute_reply":"2022-01-31T18:19:23.845369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding ordinal columns in the train set\ntrain = ordinal_encode(train)\ntrain.head()","metadata":{"id":"6bngnIoYT6YE","execution":{"iopub.status.busy":"2022-01-31T18:19:23.847842Z","iopub.execute_input":"2022-01-31T18:19:23.848261Z","iopub.status.idle":"2022-01-31T18:19:23.913106Z","shell.execute_reply.started":"2022-01-31T18:19:23.848224Z","shell.execute_reply":"2022-01-31T18:19:23.912204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making sure the columns are encoded correctly\ntrain[ordcols].head()","metadata":{"id":"xmpTHaeW7oDS","outputId":"43d6d2de-fcc9-4c17-b8cc-1fdb63ee3157","execution":{"iopub.status.busy":"2022-01-31T18:19:23.915887Z","iopub.execute_input":"2022-01-31T18:19:23.916334Z","iopub.status.idle":"2022-01-31T18:19:23.952118Z","shell.execute_reply.started":"2022-01-31T18:19:23.916292Z","shell.execute_reply":"2022-01-31T18:19:23.951325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving remaining categorical features to a variable\nobjectcols = train.select_dtypes('object').columns\nobjectcols","metadata":{"id":"bxWPMA4W74Ll","outputId":"74ca7f19-e3a8-47f8-fe5a-5e4fc803dc2c","execution":{"iopub.status.busy":"2022-01-31T18:19:23.954697Z","iopub.execute_input":"2022-01-31T18:19:23.954949Z","iopub.status.idle":"2022-01-31T18:19:23.965542Z","shell.execute_reply.started":"2022-01-31T18:19:23.954921Z","shell.execute_reply":"2022-01-31T18:19:23.964629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numcols = [col for col in train.columns if col not in objectcols and col not in ordcols]\ntrain[numcols].hist(figsize = (15,10),xlabelsize=0,ylabelsize=0,bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:23.96699Z","iopub.execute_input":"2022-01-31T18:19:23.967427Z","iopub.status.idle":"2022-01-31T18:19:36.087038Z","shell.execute_reply.started":"2022-01-31T18:19:23.967379Z","shell.execute_reply":"2022-01-31T18:19:36.086153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like some of the columns have skewed distributions, so we will apply a log transformation to relevant columns. ","metadata":{}},{"cell_type":"code","source":"#Function that transforms columns to log of columns\ncols_to_log = ['MSSubClass','LotFrontage', 'LotArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','GrLivArea',\n     'OpenPorchSF']\n\ndef log_cols(df):\n    df.loc[:,cols_to_log] = np.log(df[cols_to_log].mask(df[cols_to_log] <=0)).fillna(0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:36.088132Z","iopub.execute_input":"2022-01-31T18:19:36.088347Z","iopub.status.idle":"2022-01-31T18:19:36.094324Z","shell.execute_reply.started":"2022-01-31T18:19:36.08832Z","shell.execute_reply":"2022-01-31T18:19:36.093315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Apply log function to relevant columns and apply the result. Target column is transformed outside the function so the function can be used for the test set as well.\ntrain = log_cols(train)\ntrain['SalePrice'] = np.log(train['SalePrice'])\ntrain[numcols].hist(figsize = (15,10),xlabelsize=0,ylabelsize=0,bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:36.095451Z","iopub.execute_input":"2022-01-31T18:19:36.095664Z","iopub.status.idle":"2022-01-31T18:19:48.227726Z","shell.execute_reply.started":"2022-01-31T18:19:36.095639Z","shell.execute_reply":"2022-01-31T18:19:48.226808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the transformation, the right skewed distributions are more similar to normal distributions. ","metadata":{}},{"cell_type":"code","source":"#Encoding categorical features with one hot encoder and dropping the original columns\ndef encode_categorical(df):\n    ohe = OneHotEncoder()\n    transformed = ohe.fit_transform(df[objectcols]).toarray()\n    #Create a Pandas DataFrame of the hot encoded column\n    feature_names = ohe.get_feature_names(objectcols)\n    df = pd.concat([df.select_dtypes(exclude='object'), pd.DataFrame(transformed,columns=feature_names).astype(int)], axis=1)\n    df.drop(ordcols,axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:48.229182Z","iopub.execute_input":"2022-01-31T18:19:48.2295Z","iopub.status.idle":"2022-01-31T18:19:48.236968Z","shell.execute_reply.started":"2022-01-31T18:19:48.229458Z","shell.execute_reply":"2022-01-31T18:19:48.236035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encoding categorical columns in the train set\ntrain_enc = encode_categorical(train)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:48.238323Z","iopub.execute_input":"2022-01-31T18:19:48.238628Z","iopub.status.idle":"2022-01-31T18:19:48.288381Z","shell.execute_reply.started":"2022-01-31T18:19:48.238598Z","shell.execute_reply":"2022-01-31T18:19:48.287372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove outliers by checking Z-values of relevant clumns with a distribution that might present outliers\nstatcols = ['MasVnrArea','LotArea','2ndFlrSF','GrLivArea','LotFrontage','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','2ndFlrSF','GarageArea','OpenPorchSF','SalePrice']\nabs_z_scores = np.abs(stats.zscore(train_enc[statcols]))\nfiltered_entries = (abs_z_scores < 3.5).all(axis=1)\ntrain_enc = train_enc[filtered_entries]\ntrain_enc = train_enc.set_index('Id')\ntrain_enc.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:19:48.289676Z","iopub.execute_input":"2022-01-31T18:19:48.289903Z","iopub.status.idle":"2022-01-31T18:19:48.310685Z","shell.execute_reply.started":"2022-01-31T18:19:48.289874Z","shell.execute_reply":"2022-01-31T18:19:48.30979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the train set into X (features) and y (target)\nX_train = train_enc.drop('SalePrice',axis=1)\ny_train = train_enc['SalePrice']","metadata":{"id":"kI85h0xBFfqd","execution":{"iopub.status.busy":"2022-01-31T18:19:48.311971Z","iopub.execute_input":"2022-01-31T18:19:48.312229Z","iopub.status.idle":"2022-01-31T18:19:48.321558Z","shell.execute_reply.started":"2022-01-31T18:19:48.312201Z","shell.execute_reply":"2022-01-31T18:19:48.320667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check results of using linear regression with cross validation in the train set\nreg = LinearRegression()\nreg.fit(X_train, y_train)\nscores = cross_val_score(reg, X_train, y_train, cv=5)\nscores.mean()","metadata":{"id":"3hcF2nmkEupM","outputId":"b4f1f979-abea-4a96-99b9-555003453729","execution":{"iopub.status.busy":"2022-01-31T18:19:48.323071Z","iopub.execute_input":"2022-01-31T18:19:48.323806Z","iopub.status.idle":"2022-01-31T18:19:48.625575Z","shell.execute_reply.started":"2022-01-31T18:19:48.323757Z","shell.execute_reply":"2022-01-31T18:19:48.624711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check random forest results with cross validation in the train set\nforest = RandomForestRegressor()\nscores = cross_val_score(forest, X_train, y_train, cv=5)\nscores.mean()","metadata":{"id":"QHd_thyiHKiR","outputId":"d09c6954-b4b0-4b8c-e621-d5588b88410f","execution":{"iopub.status.busy":"2022-01-31T18:19:48.62717Z","iopub.execute_input":"2022-01-31T18:19:48.627728Z","iopub.status.idle":"2022-01-31T18:20:00.251166Z","shell.execute_reply.started":"2022-01-31T18:19:48.627681Z","shell.execute_reply":"2022-01-31T18:20:00.250301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like linear regression shows better results than Random Forest. We will continue to explore other models after some feature selection and feature engineering. ","metadata":{}},{"cell_type":"code","source":"#Check feature importances when training initial random forest model\nforest.fit(X_train,y_train)\nimportances = {'features': X_train.columns, 'importance': forest.feature_importances_}\nimp_df = pd.DataFrame(importances).sort_values(by='importance',ascending=False)\nimp_df.sort_values(by=\"importance\").plot(x='features', y='importance', kind=\"barh\",figsize = (10,40))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:20:00.252377Z","iopub.execute_input":"2022-01-31T18:20:00.252625Z","iopub.status.idle":"2022-01-31T18:20:07.62937Z","shell.execute_reply.started":"2022-01-31T18:20:00.252586Z","shell.execute_reply":"2022-01-31T18:20:07.628682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some of the top features contribute greatly to the prediction, while most of the fatures have a very minimal importance. ","metadata":{}},{"cell_type":"code","source":"#Feature selection: Once the features are ordered by importance, we check what the best cutoff is for the seleced amount of features\nmean_scores = []\nfeature_nums = np.arange(20,200,10)\nfor feature_num in feature_nums:\n    top_features = list(imp_df['features'][:feature_num])\n    X_train_mod = X_train[top_features]\n    reg = RandomForestRegressor()\n    scores = cross_val_score(reg, X_train_mod, y_train, cv=5)\n    mean_scores.append(scores.mean())\n    \nplt.plot(feature_nums,mean_scores)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:20:07.630324Z","iopub.execute_input":"2022-01-31T18:20:07.631027Z","iopub.status.idle":"2022-01-31T18:22:49.266083Z","shell.execute_reply.started":"2022-01-31T18:20:07.63098Z","shell.execute_reply":"2022-01-31T18:22:49.265135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like the number of selected features only has little impact onthe score, however, 80 features seem to show high performance, so this is the cutoff we selected","metadata":{}},{"cell_type":"code","source":"#Keep only top 80 features\nX_train_mod = X_train[list(imp_df['features'][:80])]","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:22:49.267835Z","iopub.execute_input":"2022-01-31T18:22:49.268136Z","iopub.status.idle":"2022-01-31T18:22:49.274369Z","shell.execute_reply.started":"2022-01-31T18:22:49.268107Z","shell.execute_reply":"2022-01-31T18:22:49.273406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature engineering: We used some of the most important features in various combinations and transformations to augment the data\ndef add_features(df):\n    df['Qualcond'] = df['OverallQual']*df['OverallCond']\n    df['Neighborhoodqual'] = train.groupby('Neighborhood')['OverallQual'].transform('mean')\n    df['Totalarea'] = df['GrLivArea']+df['LotArea']\n    df['HasGarage'] = np.sign(df['GarageArea'])\n    df['HasBasement'] = np.sign(df['TotalBsmtSF'])\n    df['HasFireplace'] = np.sign(df['Fireplaces'])\n    df['age'] = df['YrSold']-df['YearBuilt']\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:22:49.275417Z","iopub.execute_input":"2022-01-31T18:22:49.275662Z","iopub.status.idle":"2022-01-31T18:22:49.28862Z","shell.execute_reply.started":"2022-01-31T18:22:49.275618Z","shell.execute_reply":"2022-01-31T18:22:49.287935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding columns based on the training set before encoding, so that we can group by neighborhood\n#Then joining the added columns back to the current X_train_mod dataframe\nNewcols = ['Id','Qualcond','Neighborhoodqual','Totalarea','HasGarage','HasBasement','HasFireplace','age']\nadded_cols = add_features(train)[Newcols]\nadded_colnames = added_cols.columns\nadded_cols['Id'] = added_cols['Id'].astype('float')\nX_train_mod = X_train_mod.join(added_cols.set_index('Id') ,how='left')\nX_train_mod.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:22:49.289751Z","iopub.execute_input":"2022-01-31T18:22:49.290024Z","iopub.status.idle":"2022-01-31T18:22:49.328212Z","shell.execute_reply.started":"2022-01-31T18:22:49.289985Z","shell.execute_reply":"2022-01-31T18:22:49.327273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking performance improvement after adding features\nforest = RandomForestRegressor()\nscores = cross_val_score(reg, X_train_mod, y_train, cv=5)\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:22:49.329536Z","iopub.execute_input":"2022-01-31T18:22:49.329971Z","iopub.status.idle":"2022-01-31T18:22:58.702422Z","shell.execute_reply.started":"2022-01-31T18:22:49.329931Z","shell.execute_reply":"2022-01-31T18:22:58.701597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see an improvement in the Random Forest results.","metadata":{}},{"cell_type":"code","source":"#Checking updated feature importance\nforest.fit(X_train_mod,y_train)\nmod_importances = {'features': X_train_mod.columns, 'importance': forest.feature_importances_}\nmod_imp_df = pd.DataFrame(mod_importances).sort_values(by='importance',ascending=False)\nmod_imp_df.sort_values(by=\"importance\").plot(x='features', y='importance', kind=\"barh\",figsize = (10,20))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:22:58.70357Z","iopub.execute_input":"2022-01-31T18:22:58.703809Z","iopub.status.idle":"2022-01-31T18:23:02.732781Z","shell.execute_reply.started":"2022-01-31T18:22:58.703779Z","shell.execute_reply":"2022-01-31T18:23:02.73184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like some of the added features have high importance","metadata":{}},{"cell_type":"code","source":"#checking XGboost performance\nXgreg = xgb.XGBRegressor()\nscores = cross_val_score(Xgreg, X_train_mod, y_train, cv=5)\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:23:02.737775Z","iopub.execute_input":"2022-01-31T18:23:02.73815Z","iopub.status.idle":"2022-01-31T18:23:05.838752Z","shell.execute_reply.started":"2022-01-31T18:23:02.738105Z","shell.execute_reply":"2022-01-31T18:23:05.837892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking linear regression improvement after modifying dataset\nreg = LinearRegression()\nreg.fit(X_train_mod, y_train)\nscores = cross_val_score(reg, X_train_mod, y_train, cv=5)\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:23:05.840034Z","iopub.execute_input":"2022-01-31T18:23:05.840392Z","iopub.status.idle":"2022-01-31T18:23:05.958736Z","shell.execute_reply.started":"2022-01-31T18:23:05.840355Z","shell.execute_reply":"2022-01-31T18:23:05.957814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear regression still shows better results than Random Forest and even XGBoost.","metadata":{}},{"cell_type":"code","source":"#Finding best random forest parameters with gridsearch\nparameters = {'n_estimators':np.arange(100,1000,100), 'max_depth':np.arange(10,50,10)}\nforest = RandomForestRegressor()\nreg = GridSearchCV(forest, parameters)\nreg.fit(X_train_mod,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:23:05.960445Z","iopub.execute_input":"2022-01-31T18:23:05.96131Z","iopub.status.idle":"2022-01-31T18:50:03.678313Z","shell.execute_reply.started":"2022-01-31T18:23:05.961242Z","shell.execute_reply":"2022-01-31T18:50:03.677428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking score improvement for the best estimator\nparam_forest = reg.best_estimator_\nprint(param_forest)\nscores = cross_val_score(param_forest, X_train_mod, y_train, cv=5)\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:50:03.679906Z","iopub.execute_input":"2022-01-31T18:50:03.680232Z","iopub.status.idle":"2022-01-31T18:50:31.647234Z","shell.execute_reply.started":"2022-01-31T18:50:03.6802Z","shell.execute_reply":"2022-01-31T18:50:31.646317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like hyperparameter tuning showed some improvement for Random Forest, but not significantly. \nFor XGBoost, we tried improving some hyperparameters individually, but it seemed like the best result was achieved by the default parameters, and running grid search would take a very long time, so we kept the default for our stacked model.\nWe decided to use a stacked model for our final prediction, which consists of the tuned Random Forest, Linear regression and XGBoost. As the final estimator for the stacked model, we used XGBoost. We also tried using Linear regression as the final model, which showed great cross validation results but ran into memory issues during prediction. ","metadata":{}},{"cell_type":"code","source":"estimators = [('random_forest', RandomForestRegressor(n_estimators=500,max_depth=40)),('linear', LinearRegression()), ('xgb',xgb.XGBRegressor())]\nstack = StackingRegressor(estimators=estimators,final_estimator=xgb.XGBRegressor())\nscores = cross_val_score(stack, X_train_mod, y_train, cv=5)\nscores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:50:31.648698Z","iopub.execute_input":"2022-01-31T18:50:31.648921Z","iopub.status.idle":"2022-01-31T18:54:45.232816Z","shell.execute_reply.started":"2022-01-31T18:50:31.648895Z","shell.execute_reply":"2022-01-31T18:54:45.232226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Funcion that wraps all the preprocessing steps together\ndef preprocess(df):\n    df = replace_missingvals(df)\n    df = ordinal_encode(df)\n    df = add_features(df)\n    df = log_cols(df)\n    df = encode_categorical(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:54:45.236389Z","iopub.execute_input":"2022-01-31T18:54:45.236805Z","iopub.status.idle":"2022-01-31T18:54:45.249583Z","shell.execute_reply.started":"2022-01-31T18:54:45.236774Z","shell.execute_reply":"2022-01-31T18:54:45.248668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocess the test set\ntest = pd.read_csv('../input/house-price-feature-eng/test.csv')\ntest = preprocess(test)","metadata":{"id":"C4GF93VMP3EE","outputId":"9bf92b13-3528-4308-eaca-171b1ec4a7f0","execution":{"iopub.status.busy":"2022-01-31T18:54:45.250854Z","iopub.execute_input":"2022-01-31T18:54:45.251174Z","iopub.status.idle":"2022-01-31T18:54:45.417576Z","shell.execute_reply.started":"2022-01-31T18:54:45.25113Z","shell.execute_reply":"2022-01-31T18:54:45.416591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Keep only columns present in both the train and test set (differences are caused by ordinal encoding as well as feature selection)\ncombined = pd.concat([X_train_mod, test], join=\"inner\")\nX_train_matched = combined[:len(X_train_mod)]\ntest_matched = combined[len(X_train_mod):]\nX_train_matched.shape, test_matched.shape","metadata":{"id":"yBSebgbxSMut","outputId":"3ceb2c24-4b3e-4ab5-9cfc-73e08978128a","execution":{"iopub.status.busy":"2022-01-31T18:54:45.418845Z","iopub.execute_input":"2022-01-31T18:54:45.41906Z","iopub.status.idle":"2022-01-31T18:54:45.437697Z","shell.execute_reply.started":"2022-01-31T18:54:45.41902Z","shell.execute_reply":"2022-01-31T18:54:45.436878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the stack regressor on the train set  with only relevant columns, then create prediciton on the test set\nstack.fit(X_train_matched,y_train)\npred = stack.predict(test_matched)\npred[pred!=0] = np.exp(pred[pred!=0])\npred_df = pd.DataFrame({'Id': test.Id, 'Predicted': pred})\npred_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T18:54:45.439429Z","iopub.execute_input":"2022-01-31T18:54:45.439952Z","iopub.status.idle":"2022-01-31T18:55:48.241915Z","shell.execute_reply.started":"2022-01-31T18:54:45.439913Z","shell.execute_reply":"2022-01-31T18:55:48.241107Z"},"trusted":true},"execution_count":null,"outputs":[]}]}