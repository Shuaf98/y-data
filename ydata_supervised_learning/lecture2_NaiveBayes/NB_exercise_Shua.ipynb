{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq_3t_tluNmU"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQVMUZkQHlm2"
   },
   "source": [
    "## 1. Classifying Digits\n",
    "In this part we will test digits classification on the MNIST dataset, using Bernoulli Naive Bayes (a generative model).\n",
    "\n",
    "The MNIST dataset contains 28x28 grayscale images of handwritten digits between 0 and 9 (10 classes). For mathmatical analysis clarity, and for matching expected API, flatten each image to create a 1D array with 784 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cjwjk6pzLE-y"
   },
   "source": [
    "### Loading the MNIST dataset\n",
    "Load the MNIST data set. The digits dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. Use \n",
    ">```\n",
    "mnist = sklearn.datasets.fetch_mldata('MNIST original')\n",
    "```\n",
    "\n",
    "to fetch the original data. You may set the `data_home` to where you wish to download your data for caching. Each image is already transformed into a 1D integer array $x\\in \n",
    "[0,255]^{784}$, and the corresponding label is an integer $y\\in [0,9]$.\n",
    "\n",
    "Plot a single sample of each digit as the original image, so you get a feeling how the data looks like.\n",
    "\n",
    "Finally, divide your data into train and test sets, using 1/7 of the data for testing.\n",
    "\n",
    "---\n",
    "**Note 1:** Using `digits = sklearn.datasets.load_digits()` will only fetch a very small sample of the original set, with images resized to 8x8. \n",
    "This preprocessing of the data reduces dimensionality and gives invariance to small distortions - however, we will use the original data in this exercise. \n",
    "Feel free to test the proformance of the algorithms below on the preprocessed data as well.\n",
    "\n",
    "**Note 2:**\n",
    "Since ML-Data is deprecated, you may wish to use something like this:\n",
    ">```\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "  ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "05Om0QLxBvvT"
   },
   "outputs": [],
   "source": [
    "# data = sklearn.datasets.fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sfrie\\anaconda3\\envs\\py4dp\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#automatically splits 6:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_train[1]\n",
    "fig = plt.figure()\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "image.shape #(28 by 28, so 784 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 784) #flattent the arrays for analysis\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTGjjSKaFfE6"
   },
   "source": [
    "### Bernoulli Naive Bayes\n",
    "If we know how the digits are generated, then we know how to classify them (simply choose the digit class which will maximize the posterior probability, P(y\\x)) --- but which model should we use for describing the digits generation?\n",
    "\n",
    "In this part we will try a very simplified model of digits creation (which is obviously not the same as the \"real\" model), using a Naive Bayes over an underlying Bernoulli distribution --- that is, we will assume that given a digit class, the pixels of the images are the result of independent coin flips, each with its own \"head\" probability.\n",
    "\n",
    "Note that since we assume each pixl is either 0 (black) or 1 (white), we will need to adjust (preprocess) our data accrodingly (see below).\n",
    "\n",
    "So, the model is stated as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Domain} && x \\in \\{0,1\\}^{784} \\\\\n",
    "\\text{Prior} && \\pi_j = \\Pr(y=j) \\\\\n",
    "\\text{Likelihood} && P_j(x) = \\Pr(x | y=j) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where for each $i\\in 0\\ldots 784$ it holds that\n",
    "$$\n",
    "P_{ji}(x_i) = \\Pr(x_i | y=j) =\n",
    "\\begin{cases}\n",
    "p_{ji} & \\text{if } x_i=1 \\\\\n",
    "1-p_{ji} & \\text{if } x_i=0 \\\\\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNjhD3IpL5bC"
   },
   "source": [
    "#### Question 1\n",
    "Write the classification rule based on this Naive Bayes model. \n",
    "How would you esitmate each of the parameters of the model based on the trainning data? \n",
    "\n",
    "\n",
    "**Bonus:** Think of edge cases which may effect your estimator in an undesired way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1\n",
    "Any value above 0 will be converted to a 1, and all 0's will remain a 0. This means though, that many of our values will be \"0\", which the regular Bayes algorithm wouldn't handle well without laplace. Therefore, our updated probability is equal to:\n",
    "\n",
    "P(Xi\\y) = P(i\\y)Xi + (1-P(i\\y))(1-Xi), where Xi is either 1 or 0.\n",
    "\n",
    "P(y\\x) = argmax( P(x1\\y)*P(x2\\y) .... *P(xn\\y)*P(y) ) for each class.\n",
    "\n",
    "Prior: Probability of getting any given label (how many 1's are in the data set?)\n",
    "Likelihood: Each xi is a position in the array (the features are the positions). So given label = 3, and looking at position 0: We look at all of the position 0's for label 1, and calculate amount of 1's which appear in position 0 for 3, and calculate the amount of 0's which appear in position 0 for label 3. Each of these are the likelihoods.\n",
    "\n",
    "(We don't need the Evidence, because we are just looking for an argmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pN1prGcMqwZ"
   },
   "source": [
    "#### Answer 1\n",
    "Any value above 0 will be converted to a 1, and all 0's will remain a 0.\n",
    "\n",
    "\n",
    "P(Xi\\y) = P(i\\y)Xi + (1-P(i\\y))(1-Xi), where Xi is either 1 or 0.\n",
    "\n",
    "Prior: Probability of getting any given label (how many 1's are in the data set?)\n",
    "Likelihood: Each xi is a position in the array (the features are the positions). So given label = 3, and looking at position 0: We look at all of the position 0's for label 1, and calculate amount of 1's which appear in position 0 for 3, and calculate the amount of 0's which appear in position 0 for label 3. Each of these are the likelihoods.\n",
    "\n",
    "(We don't need the Evidence, because we are just looking for an argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10218333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For label = 3:\n",
    "prior = len(y_train[y_train == 3]) / len(y_train)\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert values greater than 0 to 1.\n",
    "x_example = x_train.copy()\n",
    "x_example[x_example > 0] =1\n",
    "\n",
    "#Looking at the 200th position\n",
    "\n",
    "samp_space = x_example[y_train== 3]\n",
    "len(samp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5633, 498)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = 350\n",
    "ones = len(samp_space[samp_space[:,loc] ==1])\n",
    "\n",
    "zeros = len(samp_space[samp_space[:,loc] ==0])\n",
    "ones, zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187734464198336"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = len(samp_space[:, loc])\n",
    "ones_prob = ones/tot\n",
    "zeros_prob = zeros/tot\n",
    "likelihood = ones_prob\n",
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08122655358016637"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09388333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood*prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this was just the calculation of the likelihood for one feature. Naive Bayes says that we can calculate the likelihood by doing\n",
    "P(x1\\y)*P(x2\\y)*P(xn\\y)*P(y).\n",
    "Therefore we would calculate the likelihood of each x, multiply them together, then multiply by the prior. \n",
    "\n",
    "We would do this for every label. We would then have 10 probabilities, and our choice would be that with the maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOnkgDIXTMCQ"
   },
   "source": [
    "#### Question 2\n",
    "Run a Naive Bayes classifier on the training data and apply predictions on the test data. Use the [sklearn.naive_bayes.BernoulliNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) implementation (see the [source code for sklearn.naive_bayes](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py) for details).\n",
    "\n",
    "Remember we need to preprocess the data in this case such that each pixel would become either black (0) or white (1). For this, use the `binarize` parameter of the implementation. Set this value to $0$ (this is the default), which in this case would mean every pixel with non-zero value will be set to 1.\n",
    "\n",
    "1. Plot the mean image of each class (estimated $\\hat{p}_{ji}$) and generate one sample of each class (remember, you can do this since this is a generative model). You will need to access the `feature_log_prob_` attribute of the trained model.\n",
    "\n",
    "2. Plot the confusion matrix of your classifier, as claculated on the test data (it is recommended to use [sklearn.metrics.confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)). Calculate the total accuracy (fraction of correctly classified images), and summarize the results in your own words.\n",
    "\n",
    "3. Think of a way you can find the optimal threshold of the binarization part. **There is no need to actually perform this task --- just describe what you would have done.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKdsdegDWaO_"
   },
   "source": [
    "#### Answer 2\n",
    "Put you answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes uses log probabilities, a thorough explanation is found in this article. The basic reason is, because the multiplication of probabilities between 0 and 1 can become unworkable, and difficult copmutationally (lots of float digits).\n",
    "\n",
    "https://www.cs.rhodes.edu/~kirlinp/courses/ai/f18/projects/proj3/naive-bayes-log-probs.pdf\n",
    "\n",
    "Notice that the log probabilites are negative probabilies. This is okay, and we don't need to swich from argmax to argmin.\n",
    "\n",
    "Example: say you have the probabilities 0.2 and 0.3. Note that ln(0.2) =  −1.6 and  ln(0.3) −1.2. The comparisons are preserved: 0.2 < 0.3 and −1.6 < −1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XalqjRWXWS-Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(binarize=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB(binarize= 0)\n",
    "clf.fit(x_train, y_train) \n",
    "#Fit here doesn't do any prediction, rather it just creates a \"bag\" of counts and probabilities for each feature and each label.\n",
    "#predict is what actually uses the Naive Bayes model, to calculate the likelihoods for each feature in the given vector(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Average Picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(clf.feature_log_prob_[i].reshape(28,28), cmap= 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Random Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af39a94708>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to generate an image\n",
    "prob = np.exp(clf.feature_log_prob_[0])\n",
    "random_nums = np.random.rand(len(clf.feature_log_prob_[0]))\n",
    "digits = []\n",
    "\n",
    "for i in range(len(prob)):\n",
    "    #The probability of a pixel being black in a digit class is high (likely part of a given class). Given a random number 'i', \n",
    "    # the more likely that this area is to be part of a class, the more likely that a random number 'i' will be smaller than that probability.\n",
    "    if random_nums[i] <= prob[i]:\n",
    "        digits.append(1)\n",
    "    else:\n",
    "        digits.append(0)\n",
    "plt.imshow(np.array(digits).reshape(28,28), cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_images(feature_log_prob):\n",
    "#     shape_n = feature_log_prob.shape[0]\n",
    "#     random_nums = np.round(np.random.rand(784), 3)\n",
    "#     pixels = np.zeros(shape_n)\n",
    "#     for i in range(shape_n):\n",
    "#         #The probability of a pixel being black in a digit class is high (likely part of a given class). Given a random number 'i', \n",
    "#         # the more likely that this area is to be part of a class, the more likely that a random number 'i' will be smaller than that probability.\n",
    "#         if random_nums[i] <= np.exp(feature_log_prob[i]):\n",
    "#             pixels[i] = 1\n",
    "#     return pixels\n",
    "\n",
    "# # plot the images\n",
    "# fig, ax = plt.subplots(10,20, figsize = (10,10))\n",
    "# for i in range(0, 20):\n",
    "#     for j in range(0, 10):\n",
    "#         temp_pix = gen_images(clf.feature_log_prob_[j])\n",
    "#         temp_pix = temp_pix.reshape(28, 28)\n",
    "#         temp_pix = 1 - temp_pix # give it a white background\n",
    "#         ax[j,i].imshow(temp_pix, cmap = 'gray')\n",
    "#         ax[j,i].set_xticks([])\n",
    "#         ax[j,i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8413,\n",
      "confusion matrix: \n",
      "[[ 887    0    4    7    2   41   16    1   22    0]\n",
      " [   0 1085   10    5    0    9    6    0   19    1]\n",
      " [  19    8  852   29   17    4   32   14   55    2]\n",
      " [   5   15   34  844    0   13    9   15   49   26]\n",
      " [   2    6    4    0  795    4   21    1   23  126]\n",
      " [  23   12    7  129   30  627   16    8   21   19]\n",
      " [  18   18   15    2   13   35  851    0    6    0]\n",
      " [   1   24   14    4   15    0    0  871   27   72]\n",
      " [  16   23   13   76   17   22    7    6  758   36]\n",
      " [   9   13    5    9   74    8    0   24   24  843]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = clf.predict(x_test)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "#accuracy = np.diagonal(conf).sum() / len(y_test)\n",
    "print(f'accuracy: {acc},\\nconfusion matrix: \\n{conf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Summary:\n",
    "\n",
    "Our classifier correctly classified each image 84% of the time. This is good, however, imporvements could be made. We made an assumption that any digit above 0 should be converted into a 1. However, we can make a better threshold for our binomial conversion, to make our model more accurate. By raising the threshold (even for each individual class) we can remove outliers for each class, and more heavily weigh the pixels which are more \"solidly\" a part of each class, as opposed to the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKSgnectrTJ1"
   },
   "source": [
    "## 2. Classifing Text Documents using Multinomial Naive Bayes\n",
    "In this exercise you will classify the \"20 newsgroups\" data set using your own naive bayes classifier and compare to the scikit learn built in version.\n",
    "\n",
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon messages posted before and after a specific date.\n",
    "\n",
    "\n",
    "* Load the **train** data using `from sklearn.datasets import fetch_20newsgroups`. remove headers, footers and quotes (see documentation)\n",
    "* Use `sklearn.feature_extraction.text import CountVectorizer` to count words (stop_words='english')\n",
    "* Write a class `NaiveBayes(BaseEstimator, ClassifierMixin)` and implement its `fit`, `predict` and `predict_proba` methods.\n",
    "* use `sklearn.pipeline.make_pipeline` to chain the vectroizer and model.\n",
    "* note: limit the vocuabolary size if you suffer memory issues\n",
    "* compare the accuracy over the **test** data. You can use `accuracy_score, classification_report`\n",
    "* compare to the built in `sklearn.naive_bayes.MultinomialNB`. If there are differences try to think why\n",
    "* plot the learning curve - is the model in the bias or variance regime (you can use the built in model for doing the analysis)\n",
    "* optimize performance in respect to vectorizer hyper parameters (e.g. max_features, max_df etc.).\n",
    "\n",
    "### Optional: Model interpretability\n",
    "Find the most important features for a **specific** decision of a NB classifier.\n",
    "Because the model has learned the prior $p(x_i|c)$ during the training, the contribution of an individual feature value can be easily measured by the posterior, $p(c|x_i)=p(c)p(x_i|c)/p(x_i)$\n",
    "Implement a function which gets a scikit-learn NB model as input and returns $P(c|x_i)$:\n",
    "\n",
    "`def calc_p_c_given_xi(model)`\n",
    "\n",
    "Hint: Use the following model properties:\n",
    "\n",
    "* `model.class_log_prior_`\n",
    "* `model.feature_log_prob_`\n",
    "\n",
    "Note: remember these are logs and you need to use np.exp and normalize to get $P(c|x_i)$ \n",
    "Another hint: use numpy built-in broadcasting property.\n",
    "\n",
    "* Use the interpretation to examine errors of the classifier where $\\hat{c}\\ne c$. Which top words support the correct class and which support the wrong class? You can use the `print_txt` below to color words. \n",
    "\n",
    "Bonus: How can you correct the analyzed error? \n",
    "\n",
    "To read more about model interpretation, see the blogpost below and my tutorial:\n",
    "* https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html\n",
    "* https://github.com/chanansh/right_but_why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WrTOhkHV9msW",
    "outputId": "c69cb41c-5ed6-4e43-ef3f-6ccaa4980c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This \u001b[42;37mword\u001b[0m support the first class but this the \u001b[41;37mother\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def print_txt(txt, hot, cold):\n",
    "  \"\"\"\n",
    "  print the text, coloring hot and cold words with colors\n",
    "  \"\"\"\n",
    "  cold_color='\\x1b[41;37m{}\\x1b[0m'\n",
    "  hot_color='\\x1b[42;37m{}\\x1b[0m'\n",
    "  def color(token):\n",
    "    lower = str(token).lower()\n",
    "    lower = lower.replace('\\t','').replace('\\n','')\n",
    "    lower = lower.translate(string.punctuation)\n",
    "    if (lower in hot) and (lower in cold):\n",
    "      return mid_color.format(token)\n",
    "    elif lower in hot:\n",
    "      return hot_color.format(token)\n",
    "    elif lower in cold:\n",
    "      return cold_color.format(token)\n",
    "    else:\n",
    "      return token\n",
    "  colored_txt = \" \".join([color(token) for token in txt.split(' ')])\n",
    "  print(colored_txt)\n",
    "print_txt('This word support the first class but this the other', ['word'],['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news = fetch_20newsgroups(remove = ('headers', 'footers', 'quotes'))\n",
    "test_news = fetch_20newsgroups(subset= 'test', remove = ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "    \"\"\" DIY binary Naive Bayes classifier based on categorical data \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\" \"\"\"\n",
    "        # self.prior = None\n",
    "        # self.word_counts = None\n",
    "        # self.lk_word = None\n",
    "        self.alpha = alpha\n",
    "        # self.is_fitted_ = False\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "\n",
    "        self.classes = np.unique(y) #len(classes)\n",
    "        self.X_by_class = np.array([X[y == c] for c in self.classes])\n",
    "        self.prior = np.array([X_class.shape[0] / len(self.classes) for X_class in self.X_by_class])\n",
    "\n",
    "        self.word_counts = []\n",
    "        self.lk_words = []\n",
    "        for matrix_per_class in self.X_by_class:\n",
    "            word_count = np.array(np.sum(matrix_per_class, axis=0)  + self.alpha).reshape(-1,1) #added dimension while creating array, reshape gets rid of it.\n",
    "            self.word_counts.append(word_count)\n",
    "\n",
    "            lk_word = word_count / np.sum(word_count)\n",
    "            self.lk_words.append(lk_word)\n",
    "\n",
    "\n",
    "    def predict_log_proba(self, x):\n",
    "        self.log_probs_perClass = [] #Not sure which order to do htis in. Getting the wrong shape of 300,20. Not sure where 300 comes from.\n",
    "        for i, text in enumerate(x.toarray()): #input is \n",
    "            text_probs = []\n",
    "            for c in self.classes:\n",
    "                word_exists = text.astype(bool)\n",
    "                lk_words_present = self.lk_words[c].reshape(1,-1)[word_exists.reshape(1,-1)] #get the value in location where there is a value (as opposed to 0)\n",
    "                text_probs.append(np.sum(np.log(lk_words_present)) + np.log(self.prior[c])) \n",
    "            self.log_probs_perClass.append(text_probs)\n",
    "        return self.log_probs_perClass\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        log_probabilities = self.predict_log_proba(x) #take out self?\n",
    "        return np.argmax(log_probabilities, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CV = CountVectorizer(stop_words= 'english')\n",
    "X = train_CV.fit_transform(train_news.data) #matrix\n",
    "y = train_news.target\n",
    "# vocab = count.vocabulary_\n",
    "\n",
    "test_CV = CountVectorizer(stop_words= 'english')\n",
    "test_x = train_CV.transform(test_news.data) #transform fits the dimensions to the fit_transform above.\n",
    "                                            #unseen words are just passed as 0 in the Naive Bayes, with laplace over it.\n",
    "test_y = test_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101322) (7532, 101322)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayes()\n",
    "NB.fit(X, y)\n",
    "# NB.predict(test_x[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is correct.\n",
    "# classes = len(np.unique(y))\n",
    "# X_by_class = np.array([X[y == c] for c in classes])\n",
    "# prior = np.array([X_class.shape[0] / len(classes) for X_class in X_by_class])\n",
    "\n",
    "# word_counts = []\n",
    "# lk_words = []\n",
    "# for matrix_per_class in X_by_class:\n",
    "#     word_count = np.array(np.sum(matrix_per_class, axis=0)  + 0.01).reshape(-1,1) #added dimension, get rid of it.\n",
    "#     word_counts.append(word_count)\n",
    "\n",
    "#     lk_word = word_count / np.sum(word_count)\n",
    "#     lk_words.append(lk_word)\n",
    "\n",
    "# log_probs_perClass = [] #Not sure which order to do htis in. Getting the wrong shape of 300,20. Not sure where 300 comes from.\n",
    "# for i, text in enumerate(test_x[:15].toarray()): #input is \n",
    "#     text_probs = []\n",
    "#     for c in classes:\n",
    "#         word_exists = text.astype(bool)\n",
    "#         lk_words_present = lk_words[c].reshape(1,-1)[word_exists.reshape(1,-1)] #get the value in location where there is a value (as opposed to 0)\n",
    "#         lk_message = np.log(lk_words_present)\n",
    "#         text_probs.append(np.sum(lk_message) + np.log(prior[c]))\n",
    "#     log_probs_perClass.append(text_probs)\n",
    "#     np.argmax(log_probs_perClass, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test = train_CV.transform(['prostoglandin, veisodilation, amoxicintamin'])\n",
    "accuracy_score([2], NB.predict(t_test))\n",
    "#even when introducing words that didn't exist in the training set, we return an answer and don't run into an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Classfication Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6192246415294742"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y[:10000], NB.predict(test_x[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84       420\n",
      "           1       0.72      0.81      0.76       511\n",
      "           2       1.00      0.04      0.09       517\n",
      "           3       0.69      0.88      0.77       523\n",
      "           4       0.95      0.85      0.90       513\n",
      "           5       0.67      0.94      0.78       531\n",
      "           6       0.93      0.83      0.88       512\n",
      "           7       0.94      0.81      0.87       522\n",
      "           8       0.97      0.82      0.89       532\n",
      "           9       0.97      0.86      0.91       545\n",
      "          10       0.63      0.93      0.75       529\n",
      "          11       0.74      0.92      0.82       518\n",
      "          12       0.93      0.79      0.85       526\n",
      "          13       0.93      0.92      0.92       533\n",
      "          14       0.92      0.88      0.90       517\n",
      "          15       0.66      0.95      0.78       524\n",
      "          16       0.87      0.90      0.89       486\n",
      "          17       0.79      0.88      0.83       505\n",
      "          18       0.78      0.91      0.84       406\n",
      "          19       0.99      0.45      0.62       330\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.85      0.81      0.79     10000\n",
      "weighted avg       0.85      0.81      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y[:10000], NB.predict(test_x[:10000]), labels = NB.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8184"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X,y)\n",
    "accuracy_score(test_y[:10000], MNB.predict(test_x[:10000]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NB exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
