{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbTSPR0dR9Ul"
   },
   "source": [
    "# Automated Spam Filtering using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95n5INsVR9Um"
   },
   "source": [
    "Credit: [@RadimRehurek](https://twitter.com/radimrehurek).\n",
    "\n",
    "Let's create an app to classify phone SMS messages in English (well, the \"SMS kind\" of English...) as either \"spam\" or \"ham\" (=not spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:14.006903Z",
     "start_time": "2020-05-05T19:34:10.315589Z"
    },
    "id": "-H4RkkDjR9Un"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.394070Z",
     "start_time": "2020-05-05T19:34:14.010870Z"
    },
    "id": "JytGjtDDR9Up",
    "outputId": "e276fb7a-7e48-4d30-d8d7-60dfe0e0c016"
   },
   "outputs": [],
   "source": [
    "# Install NLP packages\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# !pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGHLJUCGR9Uq"
   },
   "source": [
    "## Step 1: Load data, look around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_9wNmZMR9Uq"
   },
   "source": [
    "Let's first download the dataset we'll be using - go to https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection and download the zip file. Unzip it under `data` subdirectory. You should see a file called `SMSSpamCollection`, about 0.5MB in size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AThf-0QpR9Ur"
   },
   "source": [
    "```bash\n",
    "$ ls -l data\n",
    "total 1352\n",
    "-rw-r--r--@ 1 kofola  staff  477907 Mar 15  2011 SMSSpamCollection\n",
    "-rw-r--r--@ 1 kofola  staff    5868 Apr 18  2011 readme\n",
    "-rw-r-----@ 1 kofola  staff  203415 Dec  1 15:30 smsspamcollection.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p68u7iBiR9Us"
   },
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages** (see the `readme` file for more info)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRm5WyiWR9Us"
   },
   "source": [
    "We see that this is a [TSV](http://en.wikipedia.org/wiki/Tab-separated_values) (\"tab separated values\") file, where the first column is a label saying whether the given message is a normal message (\"ham\") or \"spam\". The second column is the message itself.\n",
    "\n",
    "This corpus will be our labeled training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFpD1TnfR9Ut"
   },
   "source": [
    "[![](http://radimrehurek.com/data_science_python/plot_ML_flow_chart_11.png)](http://www.astroml.org/sklearn_tutorial/general_concepts.html#supervised-learning-model-fit-x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opeZoQfYR9Uu"
   },
   "source": [
    "Instead of parsing TSV (or CSV, or Excel...) files by hand, we can use Python's `pandas` library to do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.440312Z",
     "start_time": "2020-05-05T19:34:20.397072Z"
    },
    "id": "vf7yVhvbR9Uu",
    "outputId": "a3b333ae-ef85-4142-9677-294b81a69eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570   ham               Will Ã¼ b going to esplanade fr home?\n",
      "5571   ham  Pity, * was in mood for that. So...any other s...\n",
      "5572   ham  The guy did some bitching but I acted like i'd...\n",
      "5573   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "messages = pandas.read_csv(r'C:\\Users\\sfrie\\Ydata\\ydata_supervised_learning\\lecture2_NaiveBayes\\data\\SMSSpamCollection', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mW9j0ajR9Uu"
   },
   "source": [
    "With `pandas`, we can also view aggregate statistics easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.489071Z",
     "start_time": "2020-05-05T19:34:20.444074Z"
    },
    "id": "1E3eD3YoR9Uv",
    "outputId": "951bb39b-c51d-4c93-dd72-52eb284b652e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">message</th>\n",
       "      <th>count</th>\n",
       "      <td>4827</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4518</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                              ham  \\\n",
       "message count                     4827   \n",
       "        unique                    4518   \n",
       "        top     Sorry, I'll call later   \n",
       "        freq                        30   \n",
       "\n",
       "label                                                        spam  \n",
       "message count                                                 747  \n",
       "        unique                                                653  \n",
       "        top     Please call our customer service representativ...  \n",
       "        freq                                                    4  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_amFFw6LR9Uv"
   },
   "source": [
    "How long are the messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.507076Z",
     "start_time": "2020-05-05T19:34:20.491071Z"
    },
    "id": "85GF1RyDR9Uw",
    "outputId": "8d25bc75-1d36-4a55-b23f-9750fa06e3d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text)) #take each text, calculate length (amount of letters)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.791444Z",
     "start_time": "2020-05-05T19:34:20.510076Z"
    },
    "id": "DomAv8QER9Uw",
    "outputId": "828e76b8-d7d4-41fa-b7a5-4a1b506bc118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.857363Z",
     "start_time": "2020-05-05T19:34:20.793388Z"
    },
    "id": "MXzhSSpmR9Ux",
    "outputId": "56171f8a-e9c8-4c0b-b5c2-d981935d0be0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5574.000000\n",
       "mean       80.478292\n",
       "std        59.848302\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1yO0JexR9Ux"
   },
   "source": [
    "What is that super long message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:20.871363Z",
     "start_time": "2020-05-05T19:34:20.862643Z"
    },
    "id": "tGhePn3gR9Ux",
    "outputId": "62610192-e005-430c-c179-a2eedbe4deb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\"]\n"
     ]
    }
   ],
   "source": [
    "print(list(messages.message[messages.length == 910]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSAbtjVyR9Uy"
   },
   "source": [
    "Is there any difference in message length between spam and ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:21.580709Z",
     "start_time": "2020-05-05T19:34:20.875470Z"
    },
    "id": "5flrVlM9R9Uy",
    "outputId": "101bf0e0-777b-4dc8-9c50-d88fa9431e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'ham'}>,\n",
       "       <AxesSubplot:title={'center':'spam'}>], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPERwAvWR9Uy"
   },
   "source": [
    "Good fun, but how do we make computer understand the plain text messages themselves? Or can it under such malformed gibberish at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x5QpOuiR9Uz"
   },
   "source": [
    "## Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab32qOE2R9Uz"
   },
   "source": [
    "In this section we'll massage the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "The mapping is not 1-to-1; we'll use the [bag-of-words](http://en.wikipedia.org/wiki/Bag-of-words_model) approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "As a first step, let's write a function that will split a message into its individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:21.592742Z",
     "start_time": "2020-05-05T19:34:21.585708Z"
    },
    "id": "-WKreBFKR9Uz"
   },
   "outputs": [],
   "source": [
    "def split_into_tokens(message): #split into words\n",
    "    message = message.encode('utf8').decode()  # convert bytes into proper unicode\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMP_bgDyR9Uz"
   },
   "source": [
    "Here are some of the original texts again:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:21.646154Z",
     "start_time": "2020-05-05T19:34:21.595555Z"
    },
    "id": "Kg5-hJgbR9Uz",
    "outputId": "7d9f0578-a204-4f98-f05e-7826b4c29efa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    U dun say so early hor... U c already then say...\n",
       "4    Nah I don't think he goes to usf, he lives aro...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.message.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVUDu39xR9U0"
   },
   "source": [
    "...and here are the same messages, tokenized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:21.685154Z",
     "start_time": "2020-05-05T19:34:21.649146Z"
    },
    "id": "3IkOYEGaR9U0",
    "outputId": "07087cb5-d3a1-48c2-cd27-b002505598d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.message.head().apply(split_into_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epVh-28CR9U1"
   },
   "source": [
    "NLP questions:\n",
    "\n",
    "1. Do capital letters carry information?\n",
    "2. Does distinguishing inflected form (\"goes\" vs. \"go\") carry information?\n",
    "3. Do interjections, determiners carry information?\n",
    "\n",
    "In other words, we want to better \"normalize\" the text.\n",
    "\n",
    "With textblob, we'd detect [part-of-speech (POS)](http://www.ling.upenn.edu/courses/Fall_2007/ling001/penn_treebank_pos.html) tags with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie4WrpVIR9U1"
   },
   "source": [
    "and normalize words into their base form ([lemmas](http://en.wikipedia.org/wiki/Lemmatisation)) with:\n",
    "\n",
    "We want to not distniguish between different forms of the same verb. This is called lemetizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:21.885173Z",
     "start_time": "2020-05-05T19:34:21.827145Z"
    },
    "id": "WCbljhcTR9U1",
    "outputId": "7ea18139-7d9f-44f3-ffc2-e971ab016298"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sfrie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_into_lemmas(message):                       ##USe this if NOT setting ngram_range in CountVectorizer (meaning, just taking unigram)\n",
    "#     message = message.encode('utf8').decode().lower()\n",
    "#     words = TextBlob(message).words\n",
    "#     # for each word, take its \"base form\" = lemma \n",
    "#     return [word.lemma for word in words]\n",
    "\n",
    "# messages.message.head(5).apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:24.671127Z",
     "start_time": "2020-05-05T19:34:21.887145Z"
    },
    "id": "pwKXEIZ4R9U2",
    "outputId": "d195981b-10f6-48f4-b220-12f7ca36abb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazy available only in ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry in 2 a wkly comp to win fa cup fina...\n",
       "3          u dun say so early hor u c already then say\n",
       "4    nah i do n't think he go to usf he life around...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USing Ngram\n",
    "def split_into_lemmas(message): \n",
    "    message = message.encode('utf8').decode().lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return ' '.join(word.lemma for word in words)\n",
    "\n",
    "messages.message.head(5).apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLcDwS6YR9U2"
   },
   "source": [
    "Better. You can probably think of many more ways to improve the preprocessing: decoding HTML entities (those `&amp;` and `&lt;` we saw above); filtering out stop words (pronouns etc); adding more features, such as an word-in-all-caps indicator and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd6sSGVyR9U2"
   },
   "source": [
    "## Step 3: Data to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRMRlm7zR9U2"
   },
   "source": [
    "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "Doing that requires essentially three steps, in the bag-of-words model:\n",
    "\n",
    "1. counting how many times does a word occur in each message (term frequency)\n",
    "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "3. normalizing the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPyPZxOGR9U3"
   },
   "source": [
    "Each vector has as many dimensions as there are unique words in the SMS corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452454940957116"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1- messages.label.value_counts()[1]/ messages.label.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 5574\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "    #for simplicity we don't have a validation set, because validation is used to train hypterparameters.\n",
    "    #\n",
    "print( len(msg_train), len(msg_test), len(msg_train) + len(msg_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:28.349134Z",
     "start_time": "2020-05-05T19:34:24.677076Z"
    },
    "id": "MMTGPXWxR9U3",
    "outputId": "a51fa3da-d4a6-411f-e6d6-5f776fd530fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160\n"
     ]
    }
   ],
   "source": [
    "# bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(msg_train)     #UNIGRAM\n",
    "# print(len(bow_transformer.vocabulary_)) #This value will change every time you spliot the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128155\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(ngram_range=(3,5)).fit(msg_train.apply(split_into_lemmas))\n",
    "print(len(bow_transformer.vocabulary_)) #This value will change every time you spliot the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4WbQSeHR9U3"
   },
   "source": [
    "Here we used `scikit-learn` (`sklearn`), a powerful Python library for teaching machine learning. It contains a multitude of various methods and options.\n",
    "\n",
    "Let's take one text message and get its bag-of-words counts as a vector, putting to use our new `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:28.368393Z",
     "start_time": "2020-05-05T19:34:28.356073Z"
    },
    "id": "aLVdOiONR9U3",
    "outputId": "d12262a9-b960-4435-e4c8-4be5746c75e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:28.389067Z",
     "start_time": "2020-05-05T19:34:28.375068Z"
    },
    "id": "w2t3uTGLR9U4",
    "outputId": "74f3a99c-d01e-4c59-f598-fdf8e27fb53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5198)\t1\n",
      "  (0, 29187)\t1\n",
      "  (0, 29188)\t1\n",
      "  (0, 29189)\t1\n",
      "  (0, 29432)\t1\n",
      "  (0, 29433)\t1\n",
      "  (0, 29434)\t1\n",
      "  (0, 46596)\t1\n",
      "  (0, 46597)\t1\n",
      "  (0, 86923)\t1\n",
      "  (0, 86924)\t1\n",
      "  (0, 86925)\t1\n",
      "  (0, 91187)\t1\n",
      "  (0, 91188)\t1\n",
      "  (0, 91189)\t1\n",
      "(1, 128155)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(3, 5))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTTc_tmJR9U4"
   },
   "source": [
    "7902 is the vocabulary size. This shows...\n",
    "\n",
    "So, nine unique words in message nr. 4, two of them appear twice, the rest only once. Sanity check: what are these words the appear twice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGYFr8vtR9U4"
   },
   "source": [
    "The bag-of-words counts for the entire SMS corpus are a large, sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:31.923955Z",
     "start_time": "2020-05-05T19:34:28.445119Z"
    },
    "id": "qaa_kscNR9U4",
    "outputId": "9d2c9c03-f92c-4efb-e9fd-bb071a4a325b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (4459, 128155)\n",
      "number of non-zeros: 122706\n",
      "sparsity: 0.02%\n"
     ]
    }
   ],
   "source": [
    "messages_bow_train = bow_transformer.transform(msg_train) #Once We have done fit_transform, we then do transform on new messages\n",
    "                                                            #This keeps the messages matrix to the size of the fitted data\n",
    "messages_bow_test = bow_transformer.transform(msg_test)\n",
    "\n",
    "print( 'sparse matrix shape:', messages_bow_train.shape)\n",
    "print( 'number of non-zeros:', messages_bow_train.nnz)\n",
    "print( 'sparsity: %.2f%%' % (100.0 * messages_bow_train.nnz / (messages_bow_train.shape[0] * messages_bow_train.shape[1])))\n",
    "#Sparsity of the vectors is equal to how non zero entries we have, divided by the... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNraAd-GR9U6"
   },
   "source": [
    "There are a multitude of ways in which data can be proprocessed and vectorized. These two steps, also called \"feature engineering\", are typically the most time consuming and \"unsexy\" parts of building a predictive pipeline, but they are very important and require some experience. The trick is to evaluate constantly: analyze model for the errors it makes, improve data cleaning & preprocessing, brainstorm for new features, evaluate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBQWrgGIR9U6"
   },
   "source": [
    "## Step 4: Training a model, detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLS-D4xjR9U6"
   },
   "source": [
    "With messages represented as vectors, we can finally train our spam/ham classifier. This part is pretty straightforward, and there are many libraries that realize the training algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9Rmjgr1R9U6"
   },
   "source": [
    "We'll be using scikit-learn here, choosing the [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:32.021914Z",
     "start_time": "2020-05-05T19:34:31.987893Z"
    },
    "id": "no_6huPFR9U6",
    "outputId": "d55e6214-0579-4161-df32-8280c1d130f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time spam_detector = MultinomialNB().fit(messages_bow_train, label_train)\n",
    "#multinomialNB does all of the calculations for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKHevG6bR9U7"
   },
   "source": [
    "Hooray! You can try it with your own texts, too.\n",
    "\n",
    "A natural question is to ask, how many messages do we classify correctly overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:32.041895Z",
     "start_time": "2020-05-05T19:34:32.033893Z"
    },
    "id": "H6HKixQrR9U7",
    "outputId": "60b825b7-9067-42ab-df10-4bb4568ed7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'spam' 'ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detector.predict(messages_bow_test)\n",
    "print( all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:32.101893Z",
     "start_time": "2020-05-05T19:34:32.043893Z"
    },
    "id": "zYpKBhchR9U7",
    "outputId": "e339f013-d67b-468e-85ef-1c5010dabfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9659192825112107\n",
      "confusion matrix\n",
      " [[958   4]\n",
      " [ 34 119]]\n",
      "(row=expected, col=predicted)\n"
     ]
    }
   ],
   "source": [
    "print( 'accuracy', accuracy_score(label_test, all_predictions)) #Everything we were right on, divided by everything.\n",
    "print( 'confusion matrix\\n', confusion_matrix(label_test, all_predictions))\n",
    "#confusion matrix labels: Top row are positive samples which are ham, second row is Spam. Frist column looks \n",
    "# at positives, second looks at negatives. So there were 3 False positives, and 17 False negatives.\n",
    "print( '(row=expected, col=predicted)')\n",
    "\n",
    "#Here, we care more for precision than we do recall- we don't want to accidentally get rid of important emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:32.533200Z",
     "start_time": "2020-05-05T19:34:32.105896Z"
    },
    "id": "PoXbXY7rR9U8",
    "outputId": "48bdfd16-60f8-430c-c470-d52b76b4e8c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'predicted label')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD4CAYAAAAZ+NgoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXv0lEQVR4nO3de9xVVZ3H8c8X8IKgqXmJEAKV8PYqQ7TMnCwdNStxZvIlThYWk5dMraZ8aTlZTUzN1Mx00wzNJHUkMk1Sx1K6GGYqoqSIJKOIJIo4SWre/c0fez3Nlp7LOg9ns8/l+369zuvZt7P3OoeH77P2WnvvpYjAzCzHkLoLYGbtw4FhZtkcGGaWzYFhZtkcGGaWzYFhZtkcGDVS4buS/iDplvXYz/6SljazbHWRNFbSk5KG1l0W+0vydRj1kbQ/cCkwMSKeqrs8VZO0HPiHiLi+7rLY4LiGUa/XAMu7ISxySBpWdxmsfw6MTJLGSLpc0qOSHpP0zbR8iKQzJT0gabWk70l6RVo3TlJImiZphaQ1kj6d1k0Hzgf2TVXwz0k6VtL8dY4bknZO04dJulvSE5J+L+kTafkBklaW3rOrpF9IelzSYkmHl9ZdKOlsSVen/dwsaac+PnNP+T8g6cF06nSCpL0l/Tbt/5ul7XeS9LP0/ayRdImkLdO6i4CxwI/T5z2ttP/pklYAPystGyZpa0krJb077WOkpGWS3r++/542SBHh1wAvYCiwCPhPYASwKfCWtO6DwDJgR2AkcDlwUVo3DgjgPGA48HrgWWDXtP5YYH7pOC+bT8sC2DlNrwL2T9NbAZPS9AHAyjS9USrPp4CNgbcDT1Cc9gBcCPwvsA8wDLgEmN3H5+4p/7npMx8MPAP8CNgOGA2sBt6att8Z+GtgE2Bb4Abgq6X9LQcO6mX/30vf6/DSsmFpm4OBh9PxzgMuq/v3oZtftRegHV7AvsCjPb/E66ybB3y4ND8ReD79Z+z55d+htP4WYGqabjQwVgDHA1uss005MPZP/8GGlNZfCnw2TV8InF9adxhwTx+fu6f8o0vLHgOOKs3/EPhoH+8/Ari9NN9XYOzYy7JhpWXfAO4EHgJeWffvQze/fEqSZwzwQES80Mu6VwMPlOYfoAiL7UvLHi5N/4miJjIYf0fxH/wBSb+UtG8f5XkwIl5ap0yj16M8j5Smn+5lfiSApO0kzU6nS38ELga2GWDfAA8OsH4msAfw3Yh4LGN/VhEHRp4HgbF9NMo9RNF42WMs8AIv/0+V6ylgs54ZSa8qr4yIWyNiCkX1/EfAnD7KM0ZS+d92LPD7QZSnUV+kqB28LiK2AI4BVFrfV5dcn111qXv12xSnLSf2tOdYPRwYeW6haD/4kqQRkjaVtF9adynwMUnjJY0E/gX4fh+1kYEsAnaXtKekTYHP9qyQtLGk90p6RUQ8D/wReLGXfdxMETynSdpI0gHAu4HZgyhPozYHngQelzQa+OQ66x+haOtpxKfSzw8CXwG+52s06uPAyBARL1L8p9uZoh1hJXBUWn0BcBFFA9/9FI2CJw/yOL8DPg9cD9wLzF9nk/cBy1N1/wSKv+Dr7uM54HDgHcAa4Bzg/RFxz2DK1KDPAZOAtcDVFA3AZV8Ezky9K58YaGeS9gI+TlH+F4F/paiNnN7UUls2X7hlZtlcwzCrUbrmJPd1bd3l9ZV1ZjUbMiTv7/ZLL72U0+NUKQeGWc0kDbxRi3BgmNXMgWFmWSS1VWC40XOQJB0qaWm6GcrdfE0m6YJ0M99ddZelaj2hMdCrFTgwBiFdOHQ2xbUOuwFHS9qt3lJ1nAuBQ+suxIbQToHhU5LB2QdYFhH3AUiaDUwB7q61VB0kIm6QNK7ucmwIub0kraB9StpaRvPyG6ZW8vKbu8yy5NYuXMNob7396/mSWRuUVgmDHA6MwVlJcct7jx0o7hI1a1g7BYZPSQbnVmBCukN1Y2AqMLfmMlmbaqdTEgfGIKRb1z8C/ARYAsyJiMX1lqqzSLoUuAmYmJ7rOb3uMlWlnQLDd6ua1WjYsGExcmTeA9jWrl17W0RMrrhI/XIbhlnN2qlb1YFhVrNWOd3I4cAwq5kDw8yytFKDZg4HhlnN2ikw2qe1pQVJOq7uMnS6bviO26lb1YGxfjr+l7kFdPx33E6B4VMSsxpJcrfqYElqu6vI2q3Me+21V91FaMjYsWOZPHlyW33Hy5cvZ82aNdlVglapPeRoqcCw6i1YsKDuInS8yZMbuxjTgWFm2RwYZpbNgWFmWVqpBySHA8OsZg4MM8vmblUzy+YahpllcRuGmTXEgWFm2dopMNqntcWsQzXz5jNJH5O0WNJdki6VtKmkrSVdJ+ne9HOr0vZnqBgfeKmkQwbavwPDrEY9N5/lvDL2NRo4BZgcEXsAQymGwDgdmBcRE4B5aZ40HvBUYHeKcWzPSeMG98mBYVazJt/ePgwYLmkYsBnFAFtTgFlp/SzgiDQ9BZgdEc9GxP3AMopxg/vkwDCrWbMCIyJ+D3wFWAGsAtZGxE+B7SNiVdpmFbBdekvDYwQ7MMxq1kBgbCNpQel13Dr72Yqi1jAeeDUwQtIx/R26l2X9PkrAvSRmNWvgdGPNAAMZHQTcHxGPpv1eDrwZeETSqIhYJWkUsDpt3/AYwa5hmNUot3aRGSorgDdJ2kzFGw6kGMpzLjAtbTMNuDJNzwWmStpE0nhgAnBLfwdwDcOsZs26DiMibpZ0GbAQeAG4HZgJjATmqBifdgVwZNp+saQ5wN1p+5Mi4sX+juHAMKtZM28+i4izgLPWWfwsRW2jt+1nADNy9+/AMKtZO13p6cAwq5FvPjOzhjgwzCybA8PMsjkwzCybA8PMsnioRDNriGsYZpbNgWFm2RwYZpbFF26ZWUMcGGaWzYFhZtncrWpmWdyGYWYNcWCYWTYHhpllc2CYWTYHhpllcaOnmTWknbpVKy2ppEPTqNDLJJ1e5bHM2lWTx1atVGWBkUaBPht4B7AbcHQaLdrMShwYhX2AZRFxX0Q8B8ymGPfRzJImj3xWuSoDo+GRoc26UTsFRpWNnlkjQ6cRqI/rZVuzrtAqYZCjysDIGhk6ImZSjP+IpH6HmjfrRO4lKdwKTJA0XtLGwFSK0aLNLGm3NozKahgR8YKkjwA/AYYCF0TE4qqOZ9auWiUMclR64VZEXANcU+UxzNqdA8PMsjkwzCxLK7VP5HBgmNXMgWFm2dqpW7XPwJD0DXq50KpHRJxSSYnMukyn1DAWbLBSmHWpjmnDiIhZ5XlJIyLiqeqLZNZd2ikwBjx5krSvpLuBJWn+9ZLOqbxkZl2ina70zGlt+SpwCPAYQEQsAv6qwjKZdZVmBoakLSVdJukeSUvSH/ytJV0n6d70c6vS9mekB1wtlXTIQPvPap6NiAfXWfRiVunNbEBNrmF8Dbg2InYBXk9xZnA6MC8iJgDz0jzpgVZTgd2BQ4Fz0oOv+pQTGA9KejMQkjaW9IlUCDNbT5IYMmRI1itjX1tQ1P6/AxARz0XE4xQPruppk5wFHJGmpwCzI+LZiLgfWEbx4Ks+5QTGCcBJFA+/+T2wZ5o3syZooIaxjaQFpde6z5HZEXgU+K6k2yWdL2kEsH1ErAJIP7dL2zf8kKsBL9yKiDXAe3M+uJk1roHTjTURMbmf9cOAScDJEXGzpK+RTj/6OnQvy/p9Jk1OL8mOkn4s6VFJqyVdKWnHgd5nZnma2IaxElgZETen+csoAuQRSaPSsUYBq0vbD/iQq7KcU5L/AuYAo4BXAz8ALs0pvZn1r5kP0ImIhynaHCemRQcCd1M8uGpaWjYNuDJNzwWmStpE0nhgAnBLf8fIuZdEEXFRaf7i9GAcM2uCJl9jcTJwiYqn3N0HfICiYjBH0nRgBXAkQEQsljSHIlReAE6KiH57QPu7l2TrNPlzFYMQzaY4vzkKuHq9PpKZ/VkzAyMi7gB6a+c4sI/tZwAzcvffXw3jNoqA6Pk0x5ePA/xz7kHMrG8dcbdqRIzfkAUx60atdNl3jqznYUjag2K4w017lkXE96oqlFk36ajAkHQWcABFYFxDMVbqfMCBYdYE7RQYOSdP76FoMHk4Ij5AcX36JpWWyqyLtNPdqjmnJE9HxEuSXkjXqq+muATVzJqgVcIgR05gLJC0JXAeRc/JkwxwcYeZ5Wml2kOOnHtJPpwmz5V0LbBFRPy22mKZdY+O6FaVNKm/dRGxsJoimXWXTqlh/Hs/6wJ4e5PLYtaVOiIwIuJtG7IgZt2o49owzKxaDgwzy+bAMLNsHd9LAuBeErP110ltGD29JJtS3F+/iOJW99cBNwNvqbZoZt2hnQKjz7pQRLwt9ZQ8AEyKiMkRsRfwBorHkZtZE3TavSS7RMSdPTMRcZekPasrkll3aZUwyJETGEsknQ9cTHHB1jF4ICOzpum0wPgAcCJwapq/AfhWZSUy6yKtdLqRI+fms2cknQtcExFLN0CZzLpKR3Sr9pB0OPBlYGNgfGq/+HxEHN7swkyaNIkbb7yx2bu1khUrVtRdhI733HPPNbR9O9UwcqLtLIoBWh+HPz/GfFxlJTLrMp3WS/JCRKxtlQKbdZJWCoMcOYFxl6S/B4ZKmgCcAvy62mKZdY92CoycU5KTgd2BZynGWV3L//eYmNl66rRTkndGxKeBT/cskHQkxaDMZraeWiUMcuTUMM7IXGZmDZLEkCFDsl6toL+7Vd8BHAaMlvT10qotKEZ6NrMmaKcaRn+nJA8BC4DDKYYX6PEE8LEqC2XWTToiMCJiEbBI0hXAUxHxIoCkoXjkM7OmaafAyDkx+ikwvDQ/HLi+muKYdZ9O6yXZNCKe7JmJiCclbVZhmcy6RiuFQY6cGsZT5cf1SdoLeLq6Ipl1l06rYXwU+IGkh9L8KOCoykpk1mVapcs0R87t7bdK2gWYSPFMz3si4vnKS2bWJVql9pAj5/b2zYCPA6+JiA9JmiBpYkRcVX3xzDpbK51u5MipC30XeA7YN82vBL5QWYnMukyz2zAkDZV0u6Sr0vzWkq6TdG/6uVVp2zMkLZO0VNIhA+07JzB2ioh/A54HiIinKU5NzKwJKmj0PJWXP3f3dGBeREwA5qV5JO0GTKW4ufRQ4Jx0nVWfcgLjOUnDKR4AjKSdKO5cNbMmaGZgSNoBeCdwfmnxFGBWmp4FHFFaPjsino2I+ymGD9mnv/3n9JKcBVwLjJF0CbAfcGxW6c1sQE1uw/gqcBqweWnZ9hGxCiAiVknaLi0fDfymtN3KtKxPOb0k10laCLyJ4lTk1IhYk118M+tTz92qmbaRtKA0PzMiZpb29S5gdUTcJumAnMP3siz6e0PuYMxvpRgaMYCNgCsy32dmA2ighrEmIib3s34/4HBJh1EMcbqFpIuBRySNSrWLUcDqtP1KYEzp/TtQ3HTapwGjTdI5wAnAncBdwPGSzh7ofWaWp1ltGBFxRkTsEBHjKBozfxYRxwBzgWlps2nAlWl6LjBV0iaSxgMTgFv6O0ZODeOtwB4R0dPoOYsiPMysCTbAdRhfAuZImg6sAI4EiIjFkuYAd1M84+aknrvS+5ITGEuBsRSDMkNRhfntIAtuZiVVXbgVEb8AfpGmHwMO7GO7GcCM3P3mBMYrKcZX7amq7A38RtLcdMCmD2hk1k3a6UrPnMD4TOWlMOtiHXXzGfBoRNxdXiDpgFTlMbP11E41jJxomyPpNBWGS/oG8MWqC2bWDXJ7SFolVHIC440UjZ6/Bm6l6Kfdr8pCmXWTdgqMnFOS5ymesDWc4mKQ+yPipUpLZdZFWiUMcuTUMG6lCIy9Ka72PFrSZZWWyqyLdFoNY3pE9Fy//jAwRdL7KiyTWddopTDIkRMYt0k6BtgxIj4vaSzFxVxm1gTt1K2aU9JzKJ62dXSafwLwvSRmTdJppyRvjIhJkm4HiIg/SNq44nKZdY1WCYMcWb0k6bFdPTefbQu4l8SsCVqp9pAjJzC+TvH8i+0kzQDeA5xZaanMukhHBUZEXCLpNoq73QQcERFLBnibmWXqqMAAiIh7gHsqLotZV+q4wDCzajT4TM/aOTDMatZONYzKok3SBZJWS7qrqmOYdYJ2ug6jyrrQhRSjKZlZP9opMCo7JYmIGySNq2r/Zp2iVcIgh9swzGrUSrWHHLUHhqTjgOMAxowZM8DWZp2nnQKj9v6ciJgZEZMjYvK2225bd3HMNrghQ4ZkvVpB7TUMs27nGgYg6VLgJmCipJVp1CUzK2m3hwBX2Uty9MBbmVmrhEEOn5KY1cyBYWbZHBhmls2BYWZZfLeqmTXENQwzy+bAMLNsDgwzy9JKF2XlcGCY1cyBYWbZ3EtiZtlcwzCzLO3WhtE+dSGzDtWsu1UljZH0c0lLJC2WdGpavrWk6yTdm35uVXrPGZKWSVoq6ZCBjuHAMKtZE29vfwH4x4jYFXgTcJKk3YDTgXkRMQGYl+ZJ66YCu1M8sPucNI5ynxwYZjVrVmBExKqIWJimnwCWAKOBKcCstNks4Ig0PQWYHRHPRsT9wDJgn/6O4cAwq1kVD9BJT+x/A3AzsH1ErIIiVIDt0majgQdLb1uZlvXJjZ5mNWrw5rNtJC0ozc+MiJm97HMk8EPgoxHxx37CprcV0V8BHBhmNWug9rAmIiYPsK+NKMLikoi4PC1+RNKoiFglaRSwOi1fCZQf1b8D8FB/+/cpiVnNmthLIuA7wJKI+I/SqrnAtDQ9DbiytHyqpE0kjQcmALf0dwzXMMxq1sTrMPYD3gfcKemOtOxTwJeAOelB3CuAIwEiYrGkOcDdFD0sJ0XEi/0dwIFhVqNmXrgVEfPpvV0C4MA+3jMDmJF7DAeGWc3a6UpPB4ZZzRwYZpbNd6uaWZZ2u/nMgWFWMweGmWVzYJhZNgeGmWVzYJhZFjd6mllD3K1qZtlcwzCzbA4MM8viNgwza4gDw8yyOTDMLJsDw8yyNPgQ4No5MMxq5hrGIC1cuHDN8OHDH6i7HA3YBlhTdyE6XDt+x69pZGMHxiBFxLZ1l6ERkhYM9Nh3Wz/d8B07MMwsmwPDzLL4wq3u8hfD1FnTdfx33E69JO1T0hbU27iWVZF0gKSr0vThkk7vZ9stJX14EMf4rKRP5C5fZ5sLJb2ngWONk3TXQNttyO+4LlUMxlwVB0bNJA1t9D0RMTcivtTPJlsCDQeG1cOBYT1/Qe+RNEvSbyVdJmmztG65pM9Img8cKelgSTdJWijpB2n0bSQdmvYxH/jb0r6PlfTNNL29pCskLUqvN1MMjbeTpDskfTlt90lJt6ayfK60r09LWirpemBixuf6UNrPIkk/7PlMyUGSfiXpd5LelbYfKunLpWMfv77fbSfJDQsHRneYCMyMiNcBf+Tlf/WfiYi3ANcDZwIHRcQkYAHwcUmbAucB7wb2B17VxzG+DvwyIl4PTAIWA6cD/xMRe0bEJyUdTDHQ7j7AnsBekv5K0l7AVOANFIG0d8Znujwi9k7HWwJML60bB7wVeCdwbvoM04G1EbF32v+HVAz8a0k7BYYbPav1YETcmKYvBk4BvpLmv59+vgnYDbgx/VJsDNwE7ALcHxH3Aki6GDiul2O8HXg/QBpId62krdbZ5uD0uj3Nj6QIkM2BKyLiT+kYczM+0x6SvkBx2jMS+Elp3ZyIeAm4V9J96TMcDLyu1L7xinTs32Ucqyu0ShjkcGBUK/qZfyr9FHBdRBxd3lDSnr28f7AEfDEivr3OMT46iGNcCBwREYskHQscUFrX2+cVcHJElIMFSeMaPG7HaqfA8ClJtcZK2jdNHw3M72Wb3wD7SdoZQNJmkl4L3AOMl7RT6f29mQecmN47VNIWwBMUtYcePwE+WGobGS1pO+AG4G8kDZe0OcXpz0A2B1ZJ2gh47zrrjpQ0JJV5R2BpOvaJaXskvVbSiIzjdAWlm89yXq3ANYxqLQGmSfo2cC/wrXU3iIhH01/qSyVtkhafGRG/k3QccLWkNRRhs0cvxzgVmClpOvAicGJE3CTpRhXdlv+d2jF2BW5Kf82eBI6JiIWSvg/cATwA/CrjM/0TcHPa/k5eHkxLgV8C2wMnRMQzks6naNtYqOLgjwJHZByna7RTDUMRzar1Wlmqcl8VEb39JzcDYNKkSTF/fm8Vz780YsSI2+q+r8Y1DLOatVMNw4FRkYhYTu+nEGZ/1kpdpjkcGGY1c2CYWTYHhplla5Uu0xwODLMauQ3DzBriwDCzbA4MM8vWToHhKz3NaiTpWoqhFHKsiYhDqyzPQBwYZpatffpzzKx2Dgwzy+bAMLNsDgwzy+bAMLNs/we0DIsg6tAe8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(confusion_matrix(label_test, all_predictions), cmap=plt.cm.binary, interpolation='nearest')\n",
    "plt.title('confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('expected label')\n",
    "plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux0t_9NgR9U8"
   },
   "source": [
    "From this confusion matrix, we can compute precision and recall, or their combination (harmonic mean) F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T19:34:32.750289Z",
     "start_time": "2020-05-05T19:34:29.741Z"
    },
    "id": "D3rOLkrKR9U8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       962\n",
      "        spam       0.97      0.78      0.86       153\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.89      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KRbtkZ_R9U9"
   },
   "source": [
    "There are quite a few possible metrics for evaluating model performance. Which one is the most suitable depends on the task. For example, the cost of mispredicting \"spam\" as \"ham\" is probably much lower than mispredicting \"ham\" as \"spam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2168/470816311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mDT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mDT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages_bow_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mDT_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages_bow_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    457\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                 )\n\u001b[1;32m--> 459\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m             )\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py4dp\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "DT = RandomForestClassifier(n_estimators= 200)\n",
    "DT.fit(messages_bow_train, label_train)\n",
    "\n",
    "DT_pred = DT.predict(messages_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      1.00      0.96       962\n",
      "        spam       1.00      0.41      0.58       153\n",
      "\n",
      "    accuracy                           0.92      1115\n",
      "   macro avg       0.96      0.71      0.77      1115\n",
      "weighted avg       0.93      0.92      0.90      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, DT_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0151\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                txt nokia on to 8007 for\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0146\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                with the latest news and\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0141\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                date with the latest news\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                had your mobile 11mths update for\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                now wan na see pose\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am back bit long co of\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0080\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mobile 11mths update for free to\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                that wa my uncle ll keep\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lux costa del sol holiday or\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                butt hang up on your last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ummma will call after check\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0079\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                away call b4 10th sept take\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                we can last little while\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0017\n",
       "                \n",
       "                    &plusmn; 0.0079\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                go bathe first but my\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                you sleep you want to go\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                big butt hang up on your\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                400 xmas reward is waiting for\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                the accident you had to\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask wat present he wan\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                to buy bmw car urgently it\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.02%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 77020 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5 import show_weights\n",
    "\n",
    "show_weights(DT, feature_names= list(bow_transformer.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print most important features for 0 and for 1: https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2168/3614330491.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mXGC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mXGC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mXGC_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages_bow_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGC = XGBClassifier(n_estimators= 500)\n",
    "XGC.fit(msg_train, label_train)\n",
    "XGC_pred = XGC.predict(messages_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(label_test, XGC_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_weights\n",
    "\n",
    "show_weights(XGC, feature_names= list(bow_transformer.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=[1,3])\n",
    "\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_train_transformed_with_length = add_feature(X_train_transformed, [X_train.str.len(),\n",
    "                                                                    X_train.apply(lambda x: len(''.join([a for a in x if a.isdigit()])))])\n",
    "\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "X_test_transformed_with_length = add_feature(X_test_transformed, [X_test.str.len(),\n",
    "                                                                  X_test.apply(lambda x: len(''.join([a for a in x if a.isdigit()])))])\n",
    "\n",
    "clf = LogisticRegression(C=100)\n",
    "\n",
    "clf.fit(X_train_transformed_with_length, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test_transformed_with_length)\n",
    "\n",
    "roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_predicted),\n",
    "             columns=['Predicted Spam', \"Predicted Ham\"], index=['Actual Spam', 'Actual Ham']))\n",
    "print(f'\\nTrue Positives: {tp}')\n",
    "print(f'False Positives: {fp}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Negatives: {fn}')\n",
    "\n",
    "\n",
    "print(f'True Positive Rate: { (tp / (tp + fn))}')\n",
    "print(f'Specificity: { (tn / (tn + fp))}')\n",
    "print(f'False Positive Rate: { (fp / (fp + tn))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spam Email Detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
